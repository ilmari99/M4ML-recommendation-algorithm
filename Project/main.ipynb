{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import os\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class User:\n",
    "\n",
    "    def __init__(self, userId):\n",
    "        self.ID = userId\n",
    "        # self.movie_ratings = movie_ratings #doesn't work because it creates a reference to the same dictionary\n",
    "        self.movie_ratings = {}\n",
    "        self.added_movies = 0\n",
    "\n",
    "    def add_movie_rating(self, movieId, rating):\n",
    "        if not isinstance(movieId, int):\n",
    "            raise TypeError(\"movieId must be an integer\")\n",
    "        if movieId in self.movie_ratings.keys():\n",
    "            print(f\"User {self.ID} already rated movie {movieId}\")\n",
    "            return\n",
    "        self.added_movies += 1\n",
    "        #print(f\"User {self.ID} rated movie {movieId} with a rating of {rating}\")\n",
    "        self.movie_ratings[movieId] = rating\n",
    "\n",
    "    def __hash__(self):\n",
    "        return hash(self.ID)\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return f\"User {self.ID} rated {len(self.movie_ratings)} movies\"\n",
    "\n",
    "class Movie:\n",
    "    \"\"\" This class provides a way to store movie related information \"\"\"\n",
    "    \n",
    "    def __init__(self, movieId, title, genres=[]):\n",
    "        self.ID = movieId\n",
    "        self.title = title\n",
    "        self.genres = genres\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return f\"Movie: {self.title} ({self.ID})\"\n",
    "    \n",
    "    def __hash__(self):\n",
    "        return hash(self.ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_movies(filename, nlines=\"all\", verbose = 0) -> list[Movie]:\n",
    "    \"\"\" Reads the movies from the file and returns a list of Movie objects, where indices are sequential,\n",
    "     but movie ids are not.\n",
    "    \"\"\"\n",
    "    movies = []\n",
    "    ID = None\n",
    "    title = None\n",
    "    genres = []\n",
    "    if nlines == \"all\":\n",
    "        nlines = float(\"inf\")\n",
    "    with open(filename, \"r\",encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            # Skip the header\n",
    "            if line.startswith(\"movieId\"):\n",
    "                continue\n",
    "            if len(movies) >= nlines:\n",
    "                break\n",
    "            sp = line.strip().split(\",\")\n",
    "            if len(sp) == 3:\n",
    "                ID, title, genres = sp\n",
    "            # If the title has comma, then it is in quotes and the split is incorrect\n",
    "            elif len(sp) > 3:\n",
    "                ID = sp[0]\n",
    "                genres = sp[-1]\n",
    "                title = get_title_from_movie_data(line)\n",
    "            ID = int(ID)\n",
    "            genres = genres.split(\"|\")\n",
    "            movie = Movie(ID, title, genres)\n",
    "            movies.append(movie)\n",
    "            if verbose > 0:\n",
    "                print(movie)\n",
    "    print(f\"Read {len(movies)} movies from {filename}\")\n",
    "    return movies\n",
    "\n",
    "\n",
    "def get_title_from_movie_data(line : str) -> str:\n",
    "    \"\"\" Returns the title from the movie data line, if it is in quotes\"\"\"\n",
    "    first_quote = line.find('\"')\n",
    "    last_quote = line.rfind('\"')\n",
    "    if first_quote == -1 or last_quote == -1:\n",
    "        return line.split(\",\")[1]\n",
    "    return line[first_quote+1:last_quote]\n",
    "\n",
    "\n",
    "def read_ratings(filename, nlines = \"all\", verbose=0) -> list[User]:\n",
    "    \"\"\" Reads the ratings from the file and returns a list of User objects,\n",
    "    where indices are sequential, but user ids are not.\n",
    "    \"\"\"\n",
    "    users = {}\n",
    "    read_lines = 0\n",
    "    if nlines == \"all\":\n",
    "        nlines = float(\"inf\")\n",
    "    with open(filename, \"r\") as f:\n",
    "        for line in f:\n",
    "            # Skip the header\n",
    "            if line.startswith(\"userId\"):\n",
    "                continue\n",
    "            if read_lines >= nlines:\n",
    "                break\n",
    "            read_lines += 1\n",
    "            # Split the line into the userId, movieId, rating, and timestamp\n",
    "            userId, movieId, rating, timestamp = line.strip().split(\",\")\n",
    "            userId = int(userId)\n",
    "            movieId = int(movieId)\n",
    "            rating = float(rating)\n",
    "            # Create a User object if it doesn't exist\n",
    "            if userId not in users.keys():\n",
    "                if verbose > 0:\n",
    "                    print(f\"Creating user {userId}\")\n",
    "                users[userId] = User(userId)\n",
    "            # Add the movie rating to the user\n",
    "            users[userId].add_movie_rating(movieId, rating)\n",
    "    print(f\"Read {len(users)} users from {filename}\")\n",
    "    return list(users.values())\n",
    "\n",
    "MOVIES = read_movies(\"./data/movies.csv\", nlines=\"all\", verbose=0)\n",
    "USERS = read_ratings(\"./data/ratings.csv\", nlines=\"all\", verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_user_movie_matrix(users : list[User], movies : list[Movie]) -> np.ndarray:\n",
    "    \"\"\" Create a user-movie matrix from a list of users and a list of movies.\n",
    "    The matrix is of size (len(users), len(movies)).\n",
    "    The index (i,j) of the matrix is the rating of user i for movie j.\n",
    "    If the user has not rated the movie, the value is 0.\n",
    "    The ids are sequential.\n",
    "    \"\"\"\n",
    "    # Create a matrix of zeros\n",
    "    A = np.zeros((len(users), len(movies)))\n",
    "    # Fill in the matrix with the user ratings\n",
    "    for i, user in enumerate(users):\n",
    "        for j, movie in enumerate(movies):\n",
    "            if movie.ID in user.movie_ratings:\n",
    "                A[i,j] = user.movie_ratings[movie.ID]\n",
    "                #A[i,j] = user.movie_ratings[movieid_to_sequential_movieid[str(movie.ID)]]\n",
    "    return A\n",
    "\n",
    "R = create_user_movie_matrix(USERS, MOVIES)\n",
    "print(f\"Created ratings matrix of size {R.shape}\")\n",
    "print(f\"Matrix has {np.count_nonzero(R)} ratings\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_id_conversions(make_global = False):\n",
    "    \"\"\" Reads the id conversion dictionaries from the json files and returns them.\n",
    "    If make_global is True, the dictionaries are also made global.\n",
    "\n",
    "    The dictionaries are:\n",
    "        movieid_to_sequential_movieid : Which converts an actual movie id to a sequential movie id\n",
    "        sequential_movieid_to_movieid : Which converts a sequential movie id to an actual movie id\n",
    "        userid_to_sequential_userid : Which converts an actual user id to a sequential user id\n",
    "        sequential_userid_to_userid : Which converts a sequential user id to an actual user id\n",
    "    \n",
    "    \"\"\"\n",
    "    with open(\"movieid_to_sequential_movieid.json\", \"r\") as f:\n",
    "        movieid_to_sequential_movieid = json.load(f)\n",
    "    with open(\"sequential_movieid_to_movieid.json\", \"r\") as f:\n",
    "        sequential_movieid_to_movieid = json.load(f)\n",
    "    with open(\"userid_to_sequential_userid.json\", \"r\") as f:\n",
    "        userid_to_sequential_userid = json.load(f)\n",
    "    with open(\"sequential_userid_to_userid.json\", \"r\") as f:\n",
    "        sequential_userid_to_userid = json.load(f)\n",
    "    if make_global:\n",
    "        globals()[\"movieid_to_sequential_movieid\"] = movieid_to_sequential_movieid\n",
    "        globals()[\"sequential_movieid_to_movieid\"] = sequential_movieid_to_movieid\n",
    "        globals()[\"userid_to_sequential_userid\"] = userid_to_sequential_userid\n",
    "        globals()[\"sequential_userid_to_userid\"] = sequential_userid_to_userid\n",
    "    return movieid_to_sequential_movieid, sequential_movieid_to_movieid, userid_to_sequential_userid, sequential_userid_to_userid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_ratings(R, split=0.1):\n",
    "    \"\"\" Removes a percentage of the ratings from the matrix R.\n",
    "    Returns a matrix R_test with only the removed ratings and a matrix R, where the corresponding values have been set to 0.\n",
    "    \"\"\"\n",
    "    # Get the number of ratings to remove\n",
    "    n_ratings = np.count_nonzero(R)\n",
    "    print(f\"Number of ratings: {n_ratings}\")\n",
    "    n_ratings_to_remove = int(n_ratings * split)\n",
    "    print(f\"Removing {n_ratings_to_remove} ratings...\")\n",
    "    # Get the indices of the non-zero elements\n",
    "    rs, cols = np.nonzero(R)\n",
    "    # Take a random sample of the indices\n",
    "    ratings_to_remove = random.sample(list(zip(rs,cols)),k=n_ratings_to_remove)\n",
    "    # Create a new matrix to store the removed ratings\n",
    "    removed_ratings = np.zeros_like(R)\n",
    "    done_ratings = set()\n",
    "    # Remove the ratings and store them in removed_ratings\n",
    "    for i,j in ratings_to_remove:\n",
    "        # Check if we have already removed this rating\n",
    "        if (i,j) in done_ratings:\n",
    "            print(f\"Already removed rating at ({i},{j})\")\n",
    "            continue\n",
    "        done_ratings.add((i,j))\n",
    "        removed_ratings[i,j] = R[i,j]\n",
    "        R[i,j] = 0\n",
    "    print(f\"Number of ratings removed: {np.count_nonzero(removed_ratings)}\")\n",
    "    return R, removed_ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_estimates(R):\n",
    "    \"\"\"\n",
    "    # Fill in the missing values in R with a global estimate\n",
    "    # The estimate consists of:\n",
    "    # 1. The mean of all ratings (global mean)\n",
    "    # 2. The mean of the ratings for the user (user mean)\n",
    "    # 3. The mean of the ratings for the movie (movie mean)\n",
    "    # The estimate, that a user i gives to a movie j,\n",
    "    # is the global mean + the difference between the user mean and the global mean + the difference between the movie mean and the global mean\n",
    "    \"\"\"\n",
    "    R_mean = np.ma.masked_equal(R, 0).mean(axis=1)\n",
    "    C_mean = np.ma.masked_equal(R, 0).mean(axis=0)\n",
    "    mean_all = np.ma.masked_equal(R, 0).mean()\n",
    "    R = np.where(R == 0, mean_all + (C_mean[np.newaxis, :] - mean_all) + (R_mean[:, np.newaxis] - mean_all), R)\n",
    "    return R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predicted_values(R_approx, removed_ratings):\n",
    "    \"\"\" Returns the values in R_approx, that were removed from R.\n",
    "    \"\"\"\n",
    "    predicted_values = np.zeros_like(R)\n",
    "    r_rows, r_cols = np.nonzero(removed_ratings)\n",
    "    for inds in zip(r_rows, r_cols):\n",
    "        i,j = inds\n",
    "        predicted_values[i,j] = R_approx[i,j]\n",
    "    return predicted_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets define a method, that factorizes the matrix R in to two matrices U and M with SVD\n",
    "def svd_U_M(R, k=10):\n",
    "    \"\"\" Returns the matrices U and M, where R = U @ M. \"\"\"\n",
    "    U, S, V = np.linalg.svd(R)\n",
    "    V = np.diag(S[0:k]) @ V[0:k,:]\n",
    "    return U[:,0:k], V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The second method factorizes the matrix R in to U and M using Gradient Descent:¨\n",
    "def grad_desc_U_M(R, k=10, lr=0.00001, threshold = 0.1, patience = 10, max_iters=1000, plot=False, verbose=1, lambda_ = 2):\n",
    "    \"\"\" Initialises two random matrices U (users x k) and M (k x movies).\n",
    "    Finds a non-negative matrix factorisation of R = U @ M.\n",
    "    \"\"\"\n",
    "    # Initialise U and M\n",
    "    U = np.random.rand(R.shape[0], k)\n",
    "    M = np.random.rand(k, R.shape[1])\n",
    "    error = float(\"inf\")\n",
    "    # Perform gradient descent\n",
    "    iters = 0\n",
    "    pat = 0\n",
    "    all_errors = []\n",
    "    errors = []\n",
    "    min_error = float(\"inf\")\n",
    "    while iters < max_iters:\n",
    "        # Check if the error hasn't decreased sufficiently\n",
    "        if pat >= patience:\n",
    "            if min(errors) > min_error - threshold:\n",
    "                break\n",
    "            else:\n",
    "                min_error = min(errors)\n",
    "                pat = 0\n",
    "                errors = []\n",
    "        iters += 1\n",
    "        # Calculate the errors matrix\n",
    "        error = R - U @ M\n",
    "        # Calculate the 'gradients'\n",
    "        U_grad = lambda_*error @ M.T\n",
    "        M_grad = lambda_*U.T @ error\n",
    "        # Apply the gradients\n",
    "        U += lr * U_grad\n",
    "        M += lr * M_grad\n",
    "        # Make sure there are no negative values\n",
    "        U[U < 0] = 0\n",
    "        M[M < 0] = 0\n",
    "        error = np.linalg.norm(error, ord=\"fro\")\n",
    "        errors.append(error)\n",
    "        all_errors.append(error)\n",
    "        pat += 1\n",
    "        if iters % verbose == 0:\n",
    "            print(f\"Iteration {iters}: Error {error}\")\n",
    "    print(f\"Converged after {iters} iterations.\")\n",
    "\n",
    "    # Check if there are any negative values\n",
    "    if np.any(U < 0) or np.any(M < 0):\n",
    "        print(\"Negative values in U or M\")\n",
    "    if plot:\n",
    "        plt.plot(all_errors)\n",
    "        plt.title(\"Convergence of gradient descent\")\n",
    "        plt.xlabel(\"Iteration\")\n",
    "        plt.ylabel(\"Reconstruction error (frobenius norm)\")\n",
    "        plt.show()  \n",
    "    return U, M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The third method factorizes the matrix R in to U and M using ALS:\n",
    "def als_U_M(R, k=10, max_iters=1000, patience=10, threshold=0.1, plot=False):\n",
    "    \"\"\" Initialises two matrices U (users x k) and M (k x movies) randomly.\n",
    "    Finds a non-negative matrix factorisation of R = U @ M using alternating least squares.\n",
    "    \"\"\"\n",
    "    # Initialise U and M\n",
    "    U = np.random.rand(R.shape[0], k)\n",
    "    M = np.random.rand(k, R.shape[1])\n",
    "    all_errors = []\n",
    "    errors = []\n",
    "    pat = 0\n",
    "    min_error = float(\"inf\")\n",
    "    # Perform alternating least squares\n",
    "    for i in range(max_iters):\n",
    "        if pat >= patience:\n",
    "            if min(errors) >= min_error - threshold:\n",
    "                break\n",
    "            else:\n",
    "                min_error = min(errors)\n",
    "                pat = 0\n",
    "                errors = []\n",
    "        # Update U\n",
    "        M_t_M = M @ M.T\n",
    "        #print(f\"M_t_M: {M_t_M.shape}\")\n",
    "        for u in range(R.shape[0]):\n",
    "            #yy = [R[u, m] * M[:,m] for m in range(R.shape[1])]\n",
    "            #yy = np.sum(yy, axis=0)\n",
    "            yy = R[u, :] @ M.T\n",
    "            #U[u] = np.linalg.pinv(M_t_M) @ yy\n",
    "            U[u] = np.linalg.solve(M_t_M, yy)\n",
    "        # Update M\n",
    "        U_t_U = U.T @ U\n",
    "        #print(f\"U_t_U: {U_t_U.shape}\")\n",
    "        for m in range(R.shape[1]):\n",
    "            #yy = [R[u, m] * U[u,:] for u in range(R.shape[0])]\n",
    "            #yy = np.sum(yy, axis=0)\n",
    "            yy = R[:, m] @ U\n",
    "            #M[:, m] = np.linalg.pinv(U_t_U) @ yy\n",
    "            M[:, m] = np.linalg.solve(U_t_U, yy)\n",
    "            #np.linalg.lstsq(U_t_U, yy, rcond=None)[0]\n",
    "        # Make sure there are no negative values\n",
    "        U[U < 0] = 0\n",
    "        M[M < 0] = 0\n",
    "        # Calculate the error\n",
    "        error = np.linalg.norm(R - U @ M, ord=\"fro\")\n",
    "        print(f\"Step {i}: Error: {error}\",)\n",
    "        errors.append(error)\n",
    "        all_errors.append(error)\n",
    "        pat += 1\n",
    "    print(f\"U: {U.shape}, M: {M.shape}\")\n",
    "    # Check if there are any negative values\n",
    "    if np.any(U < 0) or np.any(M < 0):\n",
    "        print(\"Negative values in U or M\")\n",
    "    if plot:\n",
    "        plt.plot(all_errors)\n",
    "        plt.title(\"Convergence of alternating least squares\")\n",
    "        plt.xlabel(\"Iteration\")\n",
    "        plt.ylabel(\"Reconstruction error (frobenius norm)\")\n",
    "        plt.show()\n",
    "    return U, M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, lets still define a main function, that can run any of the three methods with selected parameters, and report the results\n",
    "def main(R, k, method = \"svd\", split=0.1,method_kwargs={}, plot=False):\n",
    "    \"\"\" The main function. Runs the desired method for matrix factorization.\n",
    "    It prints the Frobenius norm of the approximate matrix, and the MSE and MAE of the predictions.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    R : np.array\n",
    "        The matrix to be factorized.\n",
    "    k : int | list[int]\n",
    "        The rank of the matrix factorization. If a list is given, the method is run for each value in the list.\n",
    "    method : str, optional\n",
    "        The method to be used for matrix factorization. The default is \"svd\".\n",
    "    split : float, optional\n",
    "        The percentage of ratings to be removed from the matrix. The default is 0.1.\n",
    "    method_kwargs : dict, optional\n",
    "        Additional keyword arguments for the method. The default is {}.\n",
    "    plot : bool, optional\n",
    "        Whether to plot the errors. The default is False. This only works, if k is a list.\n",
    "    \"\"\"\n",
    "    if plot and not isinstance(k, list):\n",
    "        raise ValueError(\"k must be a list, if plot is True\")\n",
    "    if not isinstance(k, list):\n",
    "        k = [k]\n",
    "    R_og = R.copy()\n",
    "    random.seed(42)\n",
    "    np.random.seed(42)\n",
    "    errors = []\n",
    "    for k_ in k:\n",
    "        R = R_og.copy()\n",
    "        R, removed_ratings = remove_ratings(R, split=split)\n",
    "        R = fill_estimates(R)\n",
    "        if method == \"svd\":\n",
    "            U, M = svd_U_M(R, k=k_, **method_kwargs)\n",
    "        elif method == \"als\":\n",
    "            U, M = als_U_M(R, k=k_, **method_kwargs)\n",
    "        elif method == \"gd\":\n",
    "            U, M = grad_desc_U_M(R, k=k_, **method_kwargs)\n",
    "        else:\n",
    "            raise ValueError(f\"Method {method} not implemented\")\n",
    "        \n",
    "        # Check if U and M are non-negative\n",
    "        if np.any(U < 0) or np.any(M < 0):\n",
    "            print(\"U or M are negative\")\n",
    "        R_approx = U @ M\n",
    "        err = np.linalg.norm(R_approx - R, ord=\"fro\")\n",
    "        print(f\"Reconstruction error of R: {err}\")\n",
    "        predicted_values = get_predicted_values(R_approx, removed_ratings)\n",
    "        nz_r, nz_c = np.nonzero(removed_ratings)\n",
    "        nz_inds = list(zip(nz_r, nz_c))\n",
    "        diffs = np.array([removed_ratings[i,j] - predicted_values[i,j] for i,j in nz_inds])\n",
    "        frob_preds = np.sqrt(sum(np.power(diffs, 2)))\n",
    "        mse = np.power(diffs, 2).mean()\n",
    "        mae = np.abs(diffs).mean()\n",
    "        print(f\"Frob norm of predictions: {frob_preds}\")\n",
    "        print(f\"MSE (k={k_}): {mse}\")\n",
    "        print(f\"MAE (k={k_}): {mae}\")\n",
    "        errors.append((err,mse, mae))\n",
    "    if plot:\n",
    "        methods = {\"svd\": \"SVD\", \"als\": \"ALS\", \"gd\": \"Gradient descent\"}\n",
    "        errors = np.array(errors)\n",
    "        for i in range(3):\n",
    "            fig, ax = plt.subplots()\n",
    "            ax.plot(k, errors[:,i])\n",
    "            ax.set_xlabel(\"k\")\n",
    "            ax.set_ylabel([\"Frob norm\", \"Test MSE\", \"Test MAE\"][i])\n",
    "            ax.set_title([f\"Reconstruction error of R\", f\"MSE of the removed values\", f\"MAE of the removed values\"][i] + f\" using {methods[method]}\")\n",
    "        plt.show()\n",
    "    return U,M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def project_movies(R, U, M, seq_movie_ids):\n",
    "    \"\"\" Projects the movies with the given ids into the latent space.\"\"\"\n",
    "    movie_id_to_sequential, sequential_movie_id_to_movieid, user_id_to_sequential_user_id, sequential_user_id_to_userid = get_id_conversions()\n",
    "    as_vectors = [M[:,i] for i in seq_movie_ids]\n",
    "    actual_movie_ids = [sequential_movie_id_to_movieid[i] for i in seq_movie_ids]\n",
    "    return {actual_movie_ids[i]: as_vectors[i] for i in range(len(seq_movie_ids))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now lets try SVD with k=10 on each of the methods\n",
    "#main(R, k=list(range(1,30,3)), method=\"svd\",split=0.1, plot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now lets try with Grad Descent:\n",
    "kwargs = {\"max_iters\": 5000, \"lr\": 0.00002, \"patience\": 5, \"threshold\": 0.1, \"verbose\":100, \"plot\":True}\n",
    "main(R, k=2, method=\"gd\",split=0.1, plot=False, method_kwargs=kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# And finally with ALS:\n",
    "kwargs = {\"max_iters\": 100, \"patience\": 1, \"threshold\": 0.1, \"plot\":False}\n",
    "main(R, k=list(range(1,13,1)), method=\"als\",split=0.1, plot=True, method_kwargs=kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "movie_id_to_sequential, sequential_movie_id_to_movieid, user_id_to_sequential_user_id, sequential_user_id_to_userid = get_id_conversions()\n",
    "print(sequential_movie_id_to_movieid)\n",
    "#{\"max_iters\": 2000, \"lr\": 0.00002, \"patience\": 10, \"threshold\": 0.001, \"verbose\":100, \"plot\":True}\n",
    "U,M = main(R, k=2, method=\"gd\",split=0.1, plot=False, method_kwargs = {\"max_iters\": 2000, \"lr\": 0.00002, \"patience\": 10, \"threshold\": 0.001, \"verbose\":100})\n",
    "movie_ids = random.sample(range(0,R.shape[1]), 10)\n",
    "selected_movie_ids = [1,10, 15, 47, 4993, 5952, 7153,8368, 40815, 54001, \n",
    "                      69844, 81834, 88125, 4896, 5816, 6537, 68791, 120799, 589, 1240, 6539, 45722, 53125,1407,\n",
    "                      1717, 1721, 3273, 2459, 2460, 8957]\n",
    "print(f\"Seleceted {len(selected_movie_ids)} movies\")\n",
    "selected_seq_ids = [movie_id_to_sequential[str(i)] for i in selected_movie_ids]\n",
    "fig,ax = plt.subplots()\n",
    "ax.set_xlabel(\"Latent dimension 1\")\n",
    "ax.set_ylabel(\"Latent dimension 2\")\n",
    "fig.set_size_inches(10,10)\n",
    "for seq_mov_id in selected_seq_ids:\n",
    "    movie = MOVIES[seq_mov_id]\n",
    "    as_k_vector = M[:,seq_mov_id]\n",
    "    print(f\"Movie: {movie}\")\n",
    "    print(f\"Projection: {as_k_vector}\")\n",
    "    ax.scatter(as_k_vector[0], as_k_vector[1])\n",
    "    title = movie.title.split(\"(\")[0]\n",
    "    ax.annotate(title, (as_k_vector[0], as_k_vector[1]), fontsize=8)\n",
    "box = ax.get_position()\n",
    "ax.set_position([box.x0, box.y0, box.width * 0.8, box.height])\n",
    "# Put a legend to the right of the current axis\n",
    "ax.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "184795dadf5853f0cf245ed3004b235a079eea8224a5ccb0d641dcb61055070b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
